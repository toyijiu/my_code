## 硬件架构
- 为了区分低速设备和高速设备，分别搞了北桥芯片和南桥芯片，北桥负责高速设备(cache,memory,CPU等)，南桥负责低速设备(IO)。
![硬件架构](./assets/1_1.png)
## 软件体系结构:
- 软件架构图
![软件架构](./assets/1_2.png)

- 层间通信的协议统称为接口(interface)，下层提供接口，上层使用接口。
- 除了硬件和应用程序，其他层都是中间层，是对它下面那层的包装和扩展。
- 应用程序使用的是操作系统应用程序编程接口，接口提供者就是运行库，运行库使用os提供的系统调用接口，系统调用接口以软中断的方式提供，比如linux一般用0x80号中断作为系统调用接口。os kernal层使用硬件定义的接口，这种接口一般叫做硬件规格。
- os的作用一是提供抽象的接口，二是管理硬件资源
- 多任务系统，os统一接管所有硬件资源，所有的应用程序以进程的方式运行，根据进程优先级的高低来分时获取cpu资源，os可以强制剥夺进程的cpu资源来分配给目前优先级最高的进程(抢占式)
- 驱动程序可以看做os的一部分
## 运行进程时内存不够的问题
- 早期只有物理内存，同时只运行一个进程，所以只要进程的大小不超过内存大小就行。
- 为了更好的利用硬件资源，必须同时运行多个进程，如果还是使用物理内存，有几个问题：
    - 地址空间不隔离，进程可以访问其他进程内存。
    - 内存使用率低，载入新进程如果内存不够时，需要将其他进程的数据暂时写到磁盘，后续再用，大量的IO操作。
    - 程序运行的地址不确定，导致程序重定位的问题。
- 解决方法就是增加中间层，用间接的地址访问方法，加入虚拟地址，再映射到物理地址，此时我们需要关注的就是映射表的相关实现更新等。
- 分段映射来解决第一个和第三个问题，分段隔离了不同进程的物理地址，进程只需要关注自己的虚拟地址(0x0开始)，不必关心实际的物理起始地址。但是分段不能解决内存利用率的问题，因为它都是按照程序为单位来替换内存资源。
![段映射](./assets/1_3.png)
- 解决第二个问题是用更小粒度的分割和映射方法，充分利用程序的局部性原理，方法的名字就叫分页。
- 分页把地址空间分成固定大小的页，一般os的物理页大小是4KB。虚拟空间的页叫虚拟页(VP),物理空间的页叫物理页(PP),磁盘空间的页叫磁盘页(DP).不同进程的VP可以映射到同一个PP，实现内存共享(share memory).
![映射关系](./assets/1_4.png)
- 当进程要用到VP2,VP3时，硬件会捕获这个消息(页错误)，然后os接管进程，将对应的DP从磁盘装入内存，并更新映射表。
- 页映射也可以起保护作用，os可以设置每个页的权限属性。
- 虚拟存储的实现依靠硬件MMU来支持。
![mmu](./assets/1_5.png)

## 线程基础
- 进程，将程序放入内存就叫进程（运行的程序）
- 线程由线程id，当前指令指针(PC),寄存器集合和stack组成。一般一个进程由多个线程组成，线程共享进程的data段，text段，heap等以及一些进程级资源(打开文件，信号等)。
![线程](./assets/1_6.png)
- 使用多线程原因：
    - 某个操作可能会有长时间等待，就起一个等待线程来等(异步)，其他的流程继续执行。
    - 某个操作会消耗大量时间，一个线程会导致程序和用户间的交互中断，就起2个，一个负责计算，一个负责交互。
    - 程序本身的并发操作逻辑需要多线程。
    - 硬件上多CPU或多核
    - 多线程在数据共享上效率更高。不需要IPC。
- 线程私有存储空间:
    - stack
    - 线程局部存储TLS
    - 寄存器
![线程](./assets/1_7.png)
- 线程总是并发地执行（处理器数量>=线程数时是真正的并行）。CPU分时切换线程的操作就是就是**线程调度**.
- 线程状态图:
![线程](./assets/1_8.png)
- 线程优先级调度下线程优先级改变的方式：
    - 用户指定优先级
    - 根据等待状态的频繁程度来提高/降低优先级，一般等待状态越多优先级越高(IO密集型)
    - 长时间得不到执行而被提升优先级。
- linux的多线程，linux将所有的执行实体都称为任务，任务概念上类似于一个单线程的进程，任务间可以共享内存空间，实际意义上共享了同一内存空间的多个任务构成了一个进程，这些任务也就成了这个进程的线程。fork写时复制
![线程](./assets/1_9.png)
![线程](./assets/1_10.png)
## 线程安全：
- 多个线程涉及共享内存数据时如何保持数据的一致性问题，常用方法是加锁。
    - 加锁：比如二元信号量，或者多元信号量
    - 互斥量：和二元信号量类似，不同的是信号量在整个系统可以被任意线程获取并释放，互斥量则是哪个线程获取了，就要自己负责释放，其他线程无法释放互斥量。
    - 临界区：比互斥量更加严格的同步手段，互斥量和信号量在系统的任何进程可见，一个进程创建了信号量/互斥量，另一个进程可以获取该锁。但是临界区的作用范围只限于本进程，自己创建就只能自己用，其他和互斥量相同。
    - 读写锁：分了两种获取方式：共享的和独占的，申请读锁必须没有写锁，可多次申请，申请写锁不能有读锁和写锁。
    - 条件变量：设置多个线程来等待条件变量的使能，当摸个进程唤醒该条件变量，之前等待的线程可以恢复执行。

- 可重入函数：一个函数要被重入，有两种情况。函数可重入，就表明被重入后不会产生任何不良后果：
    - 多个线程同时执行此函数
    - 函数自身调用自身(递归)
## 过度优化
- 为了防止编译器自动执行动态优化，不及时让寄存器/内存中的值保持一致等问题，可以用volatile关键字来阻止过度优化，它的作用：
    - 阻止编译器为了提高速度将一个变量写到寄存器而不写回来
    - 阻止编译器调整操作volatile变量的指令顺序
- 但是volatile无法阻止CPU动态调度换序的问题。
- 一个动态调度换序的例子，singleton模式的double-check：
```cpp
volatile T* pInst = NULL;

T* getInstance()
{
    if(pInst == NULL)
    {
        lock();
        if(pInst == NULL)
        {
            pInst = new T;
        }
        unlock();
    }
    return pInst;
}
```
双重判断让lock的调用开销降低到最小，但仍然可能出现CPU乱序执行指令的问题。
pInst = new T包含了3个动作：
1.分配内存。
2.在内存的位置上调用构造函数。
3.将内存地址赋值给pInst。
其中2和3的顺序是可以颠倒的，可能出现pInst的值已经不是NULL，但是对象还没构造完毕，另一个进程就拿着这个对象去用了。一般为了防止cpu乱序，通常是执行CPU的barrier指令。所以线程安全的代码如下：
```cpp
volatile T* pInst = NULL;

T* getInstance()
{
    if(pInst == NULL)
    {
        lock();
        if(pInst == NULL)
        {
            T* temp = new T;
            barrier(); //防止在此之前的指令交换到barrier之后，保证先完成构造，在赋值给指针
            pInst = temp;
        }
        unlock();
    }
    return pInst;
}
```
## 三种线程模型
用户使用的线程是用户态的用户线程，内核线程在kernal中，CPU来调用执行task。所以两者有个对应/映射关系
- 一对一模型：一个用户线程唯一对应一个内核线程，一般使用API或者系统调用产生的线程都是一对一线程。缺点是许多os内核线程数量有限，而且内核线程多了内核线程间的上下午切换花销大，降低用户线程的执行效率。
![一对一模型](./assets/1_11.png)
- 多对一模型：多个用户线程映射到一个内核线程，线程间切换由用户态代码来执行，缺点是如果其中一个用户线程阻塞，则所有线程都无法执行，因为此时内核线程也阻塞了。好处是上下文切换快合不限制线程数量
- 多对多模型：综合前面两者的优点